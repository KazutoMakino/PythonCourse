{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【自前AI講座】ディープラーニング基礎と実装\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n",
      "uint8 uint8 uint8 uint8\n",
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.9161 - sparse_categorical_accuracy: 0.7151\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.3297 - sparse_categorical_accuracy: 0.9017\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2621 - sparse_categorical_accuracy: 0.9222\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2190 - sparse_categorical_accuracy: 0.9354\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.1883 - sparse_categorical_accuracy: 0.9444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d45a88520>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras import layers, optimizers, metrics, losses, Model, callbacks\n",
    "\n",
    "# データセット準備\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)\n",
    "print(x_train.dtype, y_train.dtype, x_test.dtype, y_test.dtype)\n",
    "\n",
    "# 画素値を 0～255 から 0～1 に正規化\n",
    "x_train = x_train.astype(np.float32) / 255.0\n",
    "x_test = x_test.astype(np.float32) / 255.0\n",
    "\n",
    "# クラス数を算出\n",
    "classes = len(set(y_train))\n",
    "\n",
    "# モデル定義\n",
    "inputs = layers.Input(shape=x_train.shape[1:])\n",
    "x = inputs\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(units=32)(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dense(units=32)(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dense(units=32)(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dense(units=32)(x)\n",
    "x = layers.ReLU()(x)\n",
    "x = layers.Dense(units=classes)(x)\n",
    "x = layers.Softmax()(x)\n",
    "outputs = x\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "# 最適化関数，損失関数，評価関数の定義\n",
    "model.compile(\n",
    "    optimizer=optimizers.SGD(learning_rate=0.01),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "# 学習\n",
    "model.fit(x=x_train, y=y_train, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "neuron_num = 256\n",
    "rng = np.random.default_rng(seed=0)\n",
    "rng_normal = rng.normal(size=neuron_num)\n",
    "rng_xavier = rng_normal * math.sqrt(1 / neuron_num)\n",
    "rng_he = rng_normal * math.sqrt(2 / neuron_num)\n",
    "\n",
    "plt.figure(figsize=(10, 3), facecolor=\"white\")\n",
    "sns.kdeplot(rng_normal, color=\"black\", label=\"Normal\")\n",
    "sns.kdeplot(rng_xavier, color=\"red\", label=\"Xavier\")\n",
    "sns.kdeplot(rng_he, color=\"blue\", label=\"He\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### バッチ正規化"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{x_i} \\leftarrow \\frac{x_i - \\mu_B}{\\sqrt{\\sigma_B^2 + \\epsilon}}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "y_i \\leftarrow \\gamma \\hat{x_i} + \\beta\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化関数"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\theta_t \\leftarrow \\theta_{t-1} - \\eta \\frac{\\hat{m_t}}{\\sqrt{\\hat{\\nu_t}} + \\epsilon}\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\hat{m_t} \\leftarrow \\frac{m_t}{1 - \\beta_1^{(t)}} \\\\\n",
    "\\hat{\\nu_t} \\leftarrow \\frac{\\nu_t}{1 - \\beta_2^{(t)}} \\\\\n",
    "m_t \\leftarrow \\beta_1 m_{t-1} + (1 - \\beta_1) g_t \\\\\n",
    "\\nu_t \\leftarrow \\beta_2 \\nu_{t-1} + (1 - \\beta_2) g_t^2\n",
    "$$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 乱数シード値の固定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed: int = 0):\n",
    "    # os\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n",
    "    # random\n",
    "    random.seed(seed)\n",
    "    # numpy\n",
    "    np.random.seed(seed)\n",
    "    # tensorflow\n",
    "    tf.random.set_seed(seed)\n",
    "    # for GPU : https://github.com/NVIDIA/framework-determinism\n",
    "    os.environ[\"TF_DETERMINISTIC_OPS\"] = \"true\"\n",
    "    os.environ[\"TF_CUDNN_DETERMINISTIC\"] = \"true\"\n",
    "\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習問題"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q. mnist を次に指定するニューラルネットワーク構造，及び，学習方法にて学習してください．\n",
    "\n",
    "- 隠れ層４つの全結合層で，活性化関数は ReLU （各層のニューロン数の設定は自由）\n",
    "- バッチ正規化と drop out を入れる（削除割合の設定は自由）\n",
    "- 重みの初期化については，ReLU の場合は He の初期値，Softmax の場合は Xavier の初期値を用いる\n",
    "- 学習 epoch は 30 で，学習率を上限 0.01 とした warm up が 3 の cosine decay とする\n",
    "- 評価用データの結果も毎 epoch 計算させる"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 演習問題の解答"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "warm_up_epoch = 3\n",
    "max_lr = 0.01\n",
    "final_epoch = 30\n",
    "\n",
    "\n",
    "def lr_scheduler(epoch: int, _: float) -> float:\n",
    "    if epoch <= warm_up_epoch:\n",
    "        scheduled_lr = epoch / warm_up_epoch * max_lr\n",
    "    else:\n",
    "        scheduled_lr = (\n",
    "            (\n",
    "                math.cos(\n",
    "                    (epoch - warm_up_epoch) / (final_epoch - warm_up_epoch) * math.pi\n",
    "                )\n",
    "                + 1\n",
    "            )\n",
    "            * max_lr\n",
    "            / 2\n",
    "        )\n",
    "    scheduled_lr = round(scheduled_lr, ndigits=9)\n",
    "    return scheduled_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 28, 28)]          0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 784)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 128)               100480    \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 128)              512       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " re_lu (ReLU)                (None, 128)               0         \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 128)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_1 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_2 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_2 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               16512     \n",
      "                                                                 \n",
      " batch_normalization_3 (Batc  (None, 128)              512       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " re_lu_3 (ReLU)              (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      " softmax (Softmax)           (None, 10)                0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 153,354\n",
      "Trainable params: 152,330\n",
      "Non-trainable params: 1,024\n",
      "_________________________________________________________________\n",
      "Epoch 1/30\n",
      "1862/1875 [============================>.] - ETA: 0s - loss: 2.8522 - sparse_categorical_accuracy: 0.0860\n",
      "Epoch 1: val_loss improved from inf to 2.56895, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 2.8522 - sparse_categorical_accuracy: 0.0859 - val_loss: 2.5689 - val_sparse_categorical_accuracy: 0.0731 - lr: 0.0000e+00\n",
      "Epoch 2/30\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.4110 - sparse_categorical_accuracy: 0.8767\n",
      "Epoch 2: val_loss improved from 2.56895 to 0.13995, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.4105 - sparse_categorical_accuracy: 0.8768 - val_loss: 0.1399 - val_sparse_categorical_accuracy: 0.9542 - lr: 0.0033\n",
      "Epoch 3/30\n",
      "1872/1875 [============================>.] - ETA: 0s - loss: 0.2894 - sparse_categorical_accuracy: 0.9139\n",
      "Epoch 3: val_loss did not improve from 0.13995\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2894 - sparse_categorical_accuracy: 0.9140 - val_loss: 0.1506 - val_sparse_categorical_accuracy: 0.9530 - lr: 0.0067\n",
      "Epoch 4/30\n",
      "1865/1875 [============================>.] - ETA: 0s - loss: 0.2661 - sparse_categorical_accuracy: 0.9231\n",
      "Epoch 4: val_loss improved from 0.13995 to 0.11745, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.2659 - sparse_categorical_accuracy: 0.9232 - val_loss: 0.1175 - val_sparse_categorical_accuracy: 0.9651 - lr: 0.0100\n",
      "Epoch 5/30\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.2243 - sparse_categorical_accuracy: 0.9355\n",
      "Epoch 5: val_loss improved from 0.11745 to 0.11666, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2245 - sparse_categorical_accuracy: 0.9355 - val_loss: 0.1167 - val_sparse_categorical_accuracy: 0.9643 - lr: 0.0100\n",
      "Epoch 6/30\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.2016 - sparse_categorical_accuracy: 0.9404\n",
      "Epoch 6: val_loss improved from 0.11666 to 0.10218, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2017 - sparse_categorical_accuracy: 0.9404 - val_loss: 0.1022 - val_sparse_categorical_accuracy: 0.9700 - lr: 0.0099\n",
      "Epoch 7/30\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.1819 - sparse_categorical_accuracy: 0.9472\n",
      "Epoch 7: val_loss improved from 0.10218 to 0.08007, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1819 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.0801 - val_sparse_categorical_accuracy: 0.9745 - lr: 0.0097\n",
      "Epoch 8/30\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.1694 - sparse_categorical_accuracy: 0.9509\n",
      "Epoch 8: val_loss did not improve from 0.08007\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1693 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.0825 - val_sparse_categorical_accuracy: 0.9754 - lr: 0.0095\n",
      "Epoch 9/30\n",
      "1871/1875 [============================>.] - ETA: 0s - loss: 0.1569 - sparse_categorical_accuracy: 0.9542\n",
      "Epoch 9: val_loss improved from 0.08007 to 0.07439, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1570 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.0744 - val_sparse_categorical_accuracy: 0.9765 - lr: 0.0092\n",
      "Epoch 10/30\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.1459 - sparse_categorical_accuracy: 0.9571\n",
      "Epoch 10: val_loss improved from 0.07439 to 0.06567, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1458 - sparse_categorical_accuracy: 0.9571 - val_loss: 0.0657 - val_sparse_categorical_accuracy: 0.9792 - lr: 0.0088\n",
      "Epoch 11/30\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.1344 - sparse_categorical_accuracy: 0.9602\n",
      "Epoch 11: val_loss improved from 0.06567 to 0.06373, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1346 - sparse_categorical_accuracy: 0.9601 - val_loss: 0.0637 - val_sparse_categorical_accuracy: 0.9806 - lr: 0.0084\n",
      "Epoch 12/30\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.1242 - sparse_categorical_accuracy: 0.9635\n",
      "Epoch 12: val_loss did not improve from 0.06373\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1244 - sparse_categorical_accuracy: 0.9635 - val_loss: 0.0673 - val_sparse_categorical_accuracy: 0.9792 - lr: 0.0080\n",
      "Epoch 13/30\n",
      "1867/1875 [============================>.] - ETA: 0s - loss: 0.1181 - sparse_categorical_accuracy: 0.9646\n",
      "Epoch 13: val_loss improved from 0.06373 to 0.06166, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1181 - sparse_categorical_accuracy: 0.9646 - val_loss: 0.0617 - val_sparse_categorical_accuracy: 0.9813 - lr: 0.0075\n",
      "Epoch 14/30\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.1106 - sparse_categorical_accuracy: 0.9674\n",
      "Epoch 14: val_loss improved from 0.06166 to 0.05792, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.1105 - sparse_categorical_accuracy: 0.9674 - val_loss: 0.0579 - val_sparse_categorical_accuracy: 0.9828 - lr: 0.0070\n",
      "Epoch 15/30\n",
      "1874/1875 [============================>.] - ETA: 0s - loss: 0.0996 - sparse_categorical_accuracy: 0.9701\n",
      "Epoch 15: val_loss did not improve from 0.05792\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0996 - sparse_categorical_accuracy: 0.9701 - val_loss: 0.0600 - val_sparse_categorical_accuracy: 0.9814 - lr: 0.0064\n",
      "Epoch 16/30\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.0958 - sparse_categorical_accuracy: 0.9714\n",
      "Epoch 16: val_loss did not improve from 0.05792\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0960 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.0594 - val_sparse_categorical_accuracy: 0.9825 - lr: 0.0059\n",
      "Epoch 17/30\n",
      "1873/1875 [============================>.] - ETA: 0s - loss: 0.0907 - sparse_categorical_accuracy: 0.9729\n",
      "Epoch 17: val_loss did not improve from 0.05792\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0909 - sparse_categorical_accuracy: 0.9729 - val_loss: 0.0593 - val_sparse_categorical_accuracy: 0.9822 - lr: 0.0053\n",
      "Epoch 18/30\n",
      "1867/1875 [============================>.] - ETA: 0s - loss: 0.0821 - sparse_categorical_accuracy: 0.9750\n",
      "Epoch 18: val_loss improved from 0.05792 to 0.05655, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0821 - sparse_categorical_accuracy: 0.9750 - val_loss: 0.0566 - val_sparse_categorical_accuracy: 0.9831 - lr: 0.0047\n",
      "Epoch 19/30\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0751 - sparse_categorical_accuracy: 0.9766\n",
      "Epoch 19: val_loss did not improve from 0.05655\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0751 - sparse_categorical_accuracy: 0.9766 - val_loss: 0.0595 - val_sparse_categorical_accuracy: 0.9823 - lr: 0.0041\n",
      "Epoch 20/30\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.0699 - sparse_categorical_accuracy: 0.9780\n",
      "Epoch 20: val_loss did not improve from 0.05655\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0699 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.0570 - val_sparse_categorical_accuracy: 0.9840 - lr: 0.0036\n",
      "Epoch 21/30\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0676 - sparse_categorical_accuracy: 0.9790\n",
      "Epoch 21: val_loss improved from 0.05655 to 0.05350, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0676 - sparse_categorical_accuracy: 0.9790 - val_loss: 0.0535 - val_sparse_categorical_accuracy: 0.9845 - lr: 0.0030\n",
      "Epoch 22/30\n",
      "1869/1875 [============================>.] - ETA: 0s - loss: 0.0622 - sparse_categorical_accuracy: 0.9810\n",
      "Epoch 22: val_loss did not improve from 0.05350\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0621 - sparse_categorical_accuracy: 0.9810 - val_loss: 0.0546 - val_sparse_categorical_accuracy: 0.9841 - lr: 0.0025\n",
      "Epoch 23/30\n",
      "1868/1875 [============================>.] - ETA: 0s - loss: 0.0609 - sparse_categorical_accuracy: 0.9814\n",
      "Epoch 23: val_loss improved from 0.05350 to 0.05192, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0611 - sparse_categorical_accuracy: 0.9814 - val_loss: 0.0519 - val_sparse_categorical_accuracy: 0.9852 - lr: 0.0020\n",
      "Epoch 24/30\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0559 - sparse_categorical_accuracy: 0.9825\n",
      "Epoch 24: val_loss improved from 0.05192 to 0.05004, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0558 - sparse_categorical_accuracy: 0.9826 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9855 - lr: 0.0016\n",
      "Epoch 25/30\n",
      "1866/1875 [============================>.] - ETA: 0s - loss: 0.0538 - sparse_categorical_accuracy: 0.9835\n",
      "Epoch 25: val_loss improved from 0.05004 to 0.04930, saving model to .\\model.h5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0539 - sparse_categorical_accuracy: 0.9835 - val_loss: 0.0493 - val_sparse_categorical_accuracy: 0.9860 - lr: 0.0012\n",
      "Epoch 26/30\n",
      "1870/1875 [============================>.] - ETA: 0s - loss: 0.0520 - sparse_categorical_accuracy: 0.9834\n",
      "Epoch 26: val_loss did not improve from 0.04930\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.0521 - sparse_categorical_accuracy: 0.9834 - val_loss: 0.0503 - val_sparse_categorical_accuracy: 0.9853 - lr: 8.2256e-04\n",
      "Epoch 27/30\n",
      "1864/1875 [============================>.] - ETA: 0s - loss: 0.0482 - sparse_categorical_accuracy: 0.9850\n",
      "Epoch 27: val_loss did not improve from 0.04930\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0484 - sparse_categorical_accuracy: 0.9850 - val_loss: 0.0500 - val_sparse_categorical_accuracy: 0.9854 - lr: 5.3184e-04\n",
      "Epoch 28/30\n",
      "1863/1875 [============================>.] - ETA: 0s - loss: 0.0475 - sparse_categorical_accuracy: 0.9853\n",
      "Epoch 28: val_loss did not improve from 0.04930\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0476 - sparse_categorical_accuracy: 0.9852 - val_loss: 0.0495 - val_sparse_categorical_accuracy: 0.9852 - lr: 3.0154e-04\n",
      "Epoch 29/30\n",
      "1862/1875 [============================>.] - ETA: 0s - loss: 0.0464 - sparse_categorical_accuracy: 0.9858\n",
      "Epoch 29: val_loss did not improve from 0.04930\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0464 - sparse_categorical_accuracy: 0.9858 - val_loss: 0.0495 - val_sparse_categorical_accuracy: 0.9853 - lr: 1.3478e-04\n",
      "Epoch 30/30\n",
      "1862/1875 [============================>.] - ETA: 0s - loss: 0.0459 - sparse_categorical_accuracy: 0.9856\n",
      "Epoch 30: val_loss did not improve from 0.04930\n",
      "1875/1875 [==============================] - 7s 4ms/step - loss: 0.0458 - sparse_categorical_accuracy: 0.9856 - val_loss: 0.0498 - val_sparse_categorical_accuracy: 0.9854 - lr: 3.3808e-05\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x13d4b17a7d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.backend.clear_session()\n",
    "gc.collect()\n",
    "\n",
    "inputs = layers.Input(shape=x_train.shape[1:])\n",
    "\n",
    "x = inputs\n",
    "x = layers.Flatten()(x)\n",
    "for i in range(4):\n",
    "    x = layers.Dense(units=128, kernel_initializer=\"he_normal\")(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "    x = layers.Dropout(rate=0.2)(x)\n",
    "x = layers.Dense(units=classes, kernel_initializer=\"glorot_uniform\")(x)\n",
    "x = layers.Softmax()(x)\n",
    "outputs = x\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=0.001),\n",
    "    loss=losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[metrics.SparseCategoricalAccuracy()],\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test, y_test),\n",
    "    batch_size=32,\n",
    "    epochs=30,\n",
    "    callbacks=[\n",
    "        callbacks.ModelCheckpoint(\n",
    "            filepath=\"./model.h5\",\n",
    "            monitor=\"val_loss\",\n",
    "            verbose=1,\n",
    "            save_best_only=True,\n",
    "            save_weights_only=False,\n",
    "            mode=\"auto\",\n",
    "            save_freq=\"epoch\",\n",
    "        ),\n",
    "        callbacks.LearningRateScheduler(\n",
    "            schedule=lr_scheduler,\n",
    "            verbose=0,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7f4300d00c020e82d8b187928799c5c30a390be7d7de211bfbda9d77d14a6e94"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
